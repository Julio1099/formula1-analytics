{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a2b1e6",
   "metadata": {},
   "source": [
    "### Job ETL: Raw -> Silver\n",
    "\n",
    "Notebook responsavel por extrair dados da camada raw, higienizar e entregar na camada silver. Execute as celulas na ordem apresentada; ajuste apenas os parametros identificados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca12d12",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c836b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when, split\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7658861",
   "metadata": {},
   "source": [
    "#### Inicialização da SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1961bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Formula1_Raw_to_Silver_Outliers\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96511977",
   "metadata": {},
   "source": [
    "#### Definição dos caminhos\n",
    "\n",
    "Definimos os caminhos para as camadas Raw (origem) e Silver (destino) e garantimos que o diretório de destino exista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c275c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de origem (RAW): C:\\Users\\julii\\OneDrive\\Documentos\\formula1-analytics\\Data Layer\\raw\\dados_originais\n",
      "Diretório de destino (SILVER): C:\\Users\\julii\\OneDrive\\Documentos\\formula1-analytics\\Data Layer\\silver\\dados_limpos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.join(\"C:\", os.sep, \"Users\", \"julii\", \"OneDrive\", \"Documentos\", \"formula1-analytics\", \"Data Layer\")\n",
    "raw_path = os.path.join(base_path, \"raw\", \"dados_originais\")\n",
    "silver_path = os.path.join(base_path, \"silver\", \"dados_limpos\")\n",
    "\n",
    "os.makedirs(silver_path, exist_ok=True)\n",
    "print(f\"Diretório de origem (RAW): {raw_path}\")\n",
    "print(f\"Diretório de destino (SILVER): {silver_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1e331",
   "metadata": {},
   "source": [
    "#### Leitura dos arquivos da camada Raw\n",
    "\n",
    "Todos os arquivos CSV da camada Raw foram carregados em DataFrames do Apache Spark. A utilização do parâmetro nullValue=\"\\\\N\" é essencial para garantir o tratamento adequado dos valores nulos presentes no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae1013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lendo arquivos da camada RAW com tratamento de nulos (\\N)... \n",
      "\n",
      " Arquivos RAW carregados com sucesso!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Lendo arquivos da camada RAW com tratamento de nulos (\\\\N)... \\n\")\n",
    "\n",
    "df_lap_times = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"lap_times.csv\"), header=True, inferSchema=True)\n",
    "df_results = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"results.csv\"), header=True, inferSchema=True)\n",
    "df_races = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"races.csv\"), header=True, inferSchema=True)\n",
    "df_drivers = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"drivers.csv\"), header=True, inferSchema=True)\n",
    "df_constructors = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"constructors.csv\"), header=True, inferSchema=True)\n",
    "df_status = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"status.csv\"), header=True, inferSchema=True)\n",
    "df_pit_stops = spark.read.option(\"nullValue\", \"\\\\N\").csv(os.path.join(raw_path, \"pit_stops.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "print(\" Arquivos RAW carregados com sucesso!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2759",
   "metadata": {},
   "source": [
    "#### Limpeza, Padronização e Remoção de Outliers\n",
    "\n",
    "As colunas das tabelas races, drivers e constructors foram limpas e renomeadas para padronização e melhor legibilidade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024eb51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Limpando, padronizando e removendo outliers para a camada Silver...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Limpando, padronizando e removendo outliers para a camada Silver...\\n\")\n",
    "\n",
    "races_silver = df_races.select(\n",
    "    col(\"raceId\").alias(\"id_corrida\"),\n",
    "    col(\"year\").alias(\"ano\"),\n",
    "    col(\"round\").alias(\"rodada\"),\n",
    "    col(\"name\").alias(\"nome_corrida\")\n",
    ")\n",
    "\n",
    "drivers_silver = df_drivers.select(\n",
    "    col(\"driverId\").alias(\"id_piloto\"),\n",
    "    col(\"forename\").alias(\"primeiro_nome_piloto\"),\n",
    "    col(\"surname\").alias(\"sobrenome_piloto\")\n",
    ")\n",
    "\n",
    "constructors_silver = df_constructors.select(\n",
    "    col(\"constructorId\").alias(\"id_equipe\"),\n",
    "    col(\"name\").alias(\"nome_equipe\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f577826",
   "metadata": {},
   "source": [
    "#### Tratamento e Remoção de Outliers em pit_stops\n",
    "\n",
    "Foi aplicada uma lógica robusta para converter a coluna duration — que apresenta variações de formato — em valores numéricos correspondentes a segundos. Em seguida, realizou-se a remoção de outliers utilizando o método IQR (Interquartile Range), garantindo maior consistência e qualidade aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689a9227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Removendo outliers de 'pit_stops' (duração)...\n",
      "      1036 outliers removidos.\n"
     ]
    }
   ],
   "source": [
    "pit_stops_cleaned = df_pit_stops.withColumn(\n",
    "    \"duracao_parada_seg\",\n",
    "    when(\n",
    "        col(\"duration\").contains(\":\"),\n",
    "        split(col(\"duration\"), \":\").getItem(0).cast(\"double\") * 60 +\n",
    "        split(col(\"duration\"), \":\").getItem(1).cast(\"double\")\n",
    "    ).otherwise(\n",
    "        col(\"duration\").cast(\"double\")\n",
    "    )\n",
    ")\n",
    "\n",
    "pit_stops_silver = pit_stops_cleaned.select(\n",
    "    col(\"raceId\").alias(\"id_corrida\"),\n",
    "    col(\"driverId\").alias(\"id_piloto\"),\n",
    "    \"duracao_parada_seg\"\n",
    ").na.drop(subset=[\"duracao_parada_seg\"])\n",
    "\n",
    "print(\"    → Removendo outliers de 'pit_stops' (duração)...\")\n",
    "if pit_stops_silver.count() > 0:\n",
    "    quantiles_pit = pit_stops_silver.stat.approxQuantile(\"duracao_parada_seg\", [0.25, 0.75], 0.01)\n",
    "    q1_pit, q3_pit = quantiles_pit[0], quantiles_pit[1]\n",
    "    if q1_pit is not None and q3_pit is not None:\n",
    "        iqr_pit = q3_pit - q1_pit\n",
    "        lower_bound_pit = q1_pit - (1.5 * iqr_pit)\n",
    "        upper_bound_pit = q3_pit + (1.5 * iqr_pit)\n",
    "        count_before_pit = pit_stops_silver.count()\n",
    "        pit_stops_silver = pit_stops_silver.filter(\n",
    "            (col(\"duracao_parada_seg\") >= lower_bound_pit) & (col(\"duracao_parada_seg\") <= upper_bound_pit)\n",
    "        )\n",
    "        count_after_pit = pit_stops_silver.count()\n",
    "        print(f\"      {count_before_pit - count_after_pit} outliers removidos.\")\n",
    "    else:\n",
    "        print(\"      Não foi possível calcular os quantis para 'pit_stops'; pulando a remoção de outliers.\")\n",
    "else:\n",
    "    print(\"      DataFrame 'pit_stops' vazio após a limpeza; pulando a remoção de outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442e3f4",
   "metadata": {},
   "source": [
    "#### Limpeza de status e results\n",
    "\n",
    "As colunas das tabelas status e results foram limpas e renomeadas para assegurar padronização e consistência nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52c946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_silver = df_status.select(\n",
    "    col(\"statusId\").alias(\"id_status\"),\n",
    "    col(\"status\").alias(\"descricao_status\")\n",
    ")\n",
    "\n",
    "results_silver = df_results.select(\n",
    "    col(\"raceId\").alias(\"id_corrida\"),\n",
    "    col(\"driverId\").alias(\"id_piloto\"),\n",
    "    col(\"constructorId\").alias(\"id_equipe\"),\n",
    "    col(\"statusId\").alias(\"id_status\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797a52d",
   "metadata": {},
   "source": [
    "#### Tratamento e Remoção de Outliers na Tabela Fato lap_times\n",
    "\n",
    "A tabela fato (lap_times_fact) foi limpa, assegurando que os valores de milissegundos fossem convertidos para formato numérico. Além disso, realizou-se a remoção de outliers relacionados ao tempo de volta, visando aprimorar a qualidade e a precisão dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "811717d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Removendo outliers de 'lap_times' (tempo da volta)...\n",
      "      18174 outliers removidos.\n",
      "\n",
      " Todas as tabelas Silver foram processadas!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lap_times_fact = df_lap_times.select(\n",
    "    col(\"raceId\").alias(\"id_corrida\"),\n",
    "    col(\"driverId\").alias(\"id_piloto\"),\n",
    "    col(\"lap\").alias(\"volta\"),\n",
    "    col(\"position\").alias(\"posicao_na_volta\"),\n",
    "    expr(\"try_cast(milliseconds as integer)\").alias(\"tempo_volta_ms\")\n",
    ").na.drop(subset=[\"tempo_volta_ms\"])\n",
    "\n",
    "print(\"    → Removendo outliers de 'lap_times' (tempo da volta)...\")\n",
    "if lap_times_fact.count() > 0:\n",
    "    quantiles_lap = lap_times_fact.stat.approxQuantile(\"tempo_volta_ms\", [0.25, 0.75], 0.01)\n",
    "    q1_lap, q3_pit = quantiles_lap[0], quantiles_lap[1]\n",
    "    if q1_lap is not None and q3_pit is not None:\n",
    "        iqr_lap = q3_pit - q1_lap\n",
    "        lower_bound_lap = q1_lap - (1.5 * iqr_lap)\n",
    "        upper_bound_lap = q3_pit + (1.5 * iqr_lap)\n",
    "        count_before_lap = lap_times_fact.count()\n",
    "        lap_times_fact = lap_times_fact.filter(\n",
    "            (col(\"tempo_volta_ms\") >= lower_bound_lap) & (col(\"tempo_volta_ms\") <= upper_bound_lap)\n",
    "        ).orderBy(col(\"id_corrida\"), col(\"id_piloto\"), col(\"volta\"))\n",
    "        count_after_pit = lap_times_fact.count()\n",
    "        print(f\"      {count_before_lap - count_after_pit} outliers removidos.\")\n",
    "    else:\n",
    "        print(\"      Não foi possível calcular os quantis para 'lap_times'; pulando a remoção de outliers.\")\n",
    "else:\n",
    "    print(\"      DataFrame 'lap_times' vazio após a limpeza; pulando a remoção de outliers.\")\n",
    "\n",
    "print(\"\\n Todas as tabelas Silver foram processadas!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d67dd",
   "metadata": {},
   "source": [
    "#### Carga (Salvar camada Silver)\n",
    "\n",
    "Nesta etapa, cada DataFrame processado foi salvo como um arquivo CSV individual na pasta correspondente à camada Silver, garantindo a organização e a separação lógica dos dados tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba89c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Salvando todas as tabelas na camada SILVER...\n",
      "\n",
      "  → Arquivo salvo: races.csv\n",
      "  → Arquivo salvo: drivers.csv\n",
      "  → Arquivo salvo: constructors.csv\n",
      "  → Arquivo salvo: pit_stops.csv\n",
      "  → Arquivo salvo: status.csv\n",
      "  → Arquivo salvo: results.csv\n",
      "  → Arquivo salvo: lap_times_fact.csv\n",
      "\n",
      " Camada Silver gerada com sucesso!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" Salvando todas as tabelas na camada SILVER...\\n\")\n",
    "\n",
    "silver_tables = {\n",
    "    \"races\": races_silver,\n",
    "    \"drivers\": drivers_silver,\n",
    "    \"constructors\": constructors_silver,\n",
    "    \"pit_stops\": pit_stops_silver,\n",
    "    \"status\": status_silver,\n",
    "    \"results\": results_silver,\n",
    "    \"lap_times_fact\": lap_times_fact\n",
    "}\n",
    "\n",
    "for name, df in silver_tables.items():\n",
    "    file_path = os.path.join(silver_path, f\"{name}.csv\")\n",
    "    df.coalesce(1).toPandas().to_csv(file_path, index=False, header=True)\n",
    "    print(f\"  → Arquivo salvo: {name}.csv\")\n",
    "\n",
    "print(\"\\n Camada Silver gerada com sucesso!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22cfbe",
   "metadata": {},
   "source": [
    "#### Validação\n",
    "\n",
    "Por fim, o resultado foi validado por meio da exibição do schema e das primeiras linhas da tabela fato principal, assegurando que todo o processo de transformação e limpeza dos dados foi executado com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ad5c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validando a tabela fato principal 'lap_times_fact':\n",
      "\n",
      "root\n",
      " |-- id_corrida: integer (nullable = true)\n",
      " |-- id_piloto: integer (nullable = true)\n",
      " |-- volta: integer (nullable = true)\n",
      " |-- posicao_na_volta: integer (nullable = true)\n",
      " |-- tempo_volta_ms: integer (nullable = true)\n",
      "\n",
      "+----------+---------+-----+----------------+--------------+\n",
      "|id_corrida|id_piloto|volta|posicao_na_volta|tempo_volta_ms|\n",
      "+----------+---------+-----+----------------+--------------+\n",
      "|         1|        1|    1|              13|        109088|\n",
      "|         1|        1|    2|              12|         93740|\n",
      "|         1|        1|    3|              11|         91600|\n",
      "|         1|        1|    4|              10|         91067|\n",
      "|         1|        1|    5|              10|         92129|\n",
      "|         1|        1|    6|               9|         90469|\n",
      "|         1|        1|    7|               9|         89488|\n",
      "|         1|        1|    8|               9|         90302|\n",
      "|         1|        1|    9|               9|         90889|\n",
      "|         1|        1|   10|               8|         92418|\n",
      "+----------+---------+-----+----------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      " Job ETL (Raw → Silver) finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(\" Validando a tabela fato principal 'lap_times_fact':\\n\")\n",
    "lap_times_fact.printSchema()\n",
    "lap_times_fact.show(10)\n",
    "\n",
    "print(\"\\n Job ETL (Raw → Silver) finalizado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
